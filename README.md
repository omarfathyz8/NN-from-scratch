# CSE473s Fall-2025 â€“ Build-Your-Own Neural-Network Library

---

## âœ… What Works Today

| Milestone | Status | Evidence |
|-----------|--------|----------|
| **Core library** | âœ… | `/lib` â€“ modular, vectorised, zero external-ML imports |
| **XOR problem** | âœ… | 2-4-1 MLP reaches **0% classification error** in &lt;1k epochs |
| **Gradient check** | âœ… | numerical vs analytical **&lt;1e-7** |

---

## ðŸ“¦ Repo Structure
```
â”œâ”€â”€ lib/               # our tiny framework
â”‚   â”œâ”€â”€ layers.py      # Dense + base Layer
â”‚   â”œâ”€â”€ activations.py # ReLU, Sigmoid, Tanh, Softmax
â”‚   â”œâ”€â”€ losses.py      # MSE
â”‚   â”œâ”€â”€ optimizers.py  # SGD
â”‚   â””â”€â”€ network.py     # Sequential container
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ project_demo.ipynb  # all runnable demos
â””â”€â”€ README.md
```

---

## ðŸšª Next Gates (in order)

1. **Auto-encoder on MNIST**  
   - 784 â†’ 32 â†’ 784, ReLU / Sigmoid, MSE loss  
   - Deliver loss-curve + original-vs-reconstructed grid

2. **Latent-SVM classifier**  
   - Freeze encoder, train `sklearn.svm.SVC` on 32-D features  
   - Report test accuracy + confusion matrix

3. **TensorFlow/Keras baseline**  
   - Replicate **exact** architectures (XOR & auto-encoder)  
   - Compare LOC, training time, final MSE, test acc

4. **Final report** (`report/project_report.pdf`)  
   - Design choices, results, comparison, lessons learnt
